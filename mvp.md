### Minimum Viable Product (MVP)


After trying out several different subsets of features, the model performed best when all features were included. With all the features included, \
F1 score was around 0.973

 Accuracy: 0.973 \
 Precision: 0.972 \
 Recall: 0.974 \
 F1: 0.973 \
 ROC: 0.996 
 
![Image of Confusion Matrix - All Features Included](https://github.com/munwonjj/Classification_Project/blob/main/confusion_matrix_graph.png)




Below are graphs for KNN, Logistic, Decision Tree, and Random Forest ROC curves

![Image of various ROC curves](https://github.com/munwonjj/Classification_Project/blob/main/all_ROC_curves.png)

Rather than focusing on one specific model, I would like to explore more with XGboost and try more feature engineering on the logistic regression.
